{
    "model_id": "Meta-Llama-3.1-8B-Instruct",
    "gguf_repo_id": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF",
    "number_of_parameters": 8,
    "f_name_for_q_bits": {
        "q8": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf",
        "q6": "Meta-Llama-3.1-8B-Instruct-Q6_K.gguf",
        "q5": "Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
        "q4": "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "q3": "Meta-Llama-3.1-8B-Instruct-Q3_K_M.gguf",
        "q2": "Meta-Llama-3.1-8B-Instruct-Q2_K.gguf"
    },
    "base_generation_prefix": "<|start_header_id|>assistant<|end_header_id|>\n\n",
    "tokenizer_preset_data": {
        "local_path": "llama/llama3_1_8b_instruct/tokenizer.json"
    },
    "tokenizer_config_preset_data": {
        "local_path": "llama/llama3_1_8b_instruct/tokenizer_config.json"
    }
}