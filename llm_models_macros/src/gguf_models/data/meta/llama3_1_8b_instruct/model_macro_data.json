{
    "model_id": "Llama-3.1-8B-Instruct-GGUF",
    "friendly_name": "Llama 3.1 8B Instruct",
    "model_repo_id": "meta-llama/Llama-3.1-8B-Instruct-GGUF",
    "gguf_repo_id": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF",
    "number_of_parameters": 8.0,
    "quant_file_names": {
        "q8": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf",
        "q6": "Meta-Llama-3.1-8B-Instruct-Q6_K.gguf",
        "q5": "Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
        "q4": "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "q3": "Meta-Llama-3.1-8B-Instruct-Q3_K_M.gguf",
        "q2": "Meta-Llama-3.1-8B-Instruct-Q2_K.gguf"
    },
    "base_generation_prefix": "<|start_header_id|>assistant<|end_header_id|>\n\n",
    "tokenizer_path": "meta/llama3_1_8b_instruct/tokenizer.json"
}